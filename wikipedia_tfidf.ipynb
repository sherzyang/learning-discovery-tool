{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"en\")\n",
    "statistics = wikipedia.search(\"statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = wikipedia.page(\"Statistics\")\n",
    "#print(statistics.title)\n",
    "#print(statistics.url)\n",
    "#print(statistics.content)\n",
    "#print(statistics.links[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Statistics is a branch of mathematics working with data collection, organization, analysis, interpretation and presentation.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.summary(\"Statistics\", sentences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install wikipedia-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install wiki-dump-reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiki_dump_reader import Cleaner, iterate\n",
    "\n",
    "corpus = []\n",
    "cleaner = Cleaner()\n",
    "for title, text in iterate('data/enwiki-latest-pages-articles.xml'):\n",
    "    text = cleaner.clean_text(text)\n",
    "    cleaned_text, links = cleaner.build_links(text)\n",
    "    corpus.append(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29316"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = []\n",
    "for i in corpus:\n",
    "    if len(i) > 100:\n",
    "        long_text.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = long_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complic'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "PorterStemmer().stem('complications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sherzyang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Louis', 'J.', 'Russell', '(circa', '1912‚Äì1973)', 'was', 'an', 'agent', 'of', 'the', 'Federal', 'Bureau', 'of', 'Investigation', '(FBI),', 'senior', 'investigator', 'of', 'the', 'House', 'Un-American', 'Activities', 'Committee', '(HUAC),', 'and', 'private', 'detective.\\n==Background==\\nLouis', 'James', 'Russell', 'graduated', 'from', 'the', 'Catholic', 'University', 'of', 'America.\\n==Career==\\nIn', '1935,', 'Russell', 'joined', 'the', 'FBI', 'as', 'an', 'agent.\\n===HUAC===\\nIn', '1945,', 'Russell', 'joined', 'HUAC', 'as', 'an', 'investigator.', '', 'Robert', 'E.', 'Stripling', 'has', 'Russell', 'testify', 'on', 'what', 'he', 'knew', 'about', 'Gerhart', 'Eisler', 'and', 'Hollywood', 'industry', 'people.', '', 'He', 'also', 'testified', 'about', 'Leon', 'Josephson', 'and', 'Alexander', 'Koral.', '', 'By', '1948,', 'Russell', 'was', 'a', 'HUAC', 'senior', 'investigator', 'in', 'the', 'Hiss-Chambers', 'case.', '', 'In', 'his', 'memoir', 'Six', 'Crises,', 'Richard', 'Nixon', 'recalled', 'that', 'Russell', 'restrained', 'Hiss', 'when', 'it', 'seemed', 'Hiss', 'was', 'about', 'to', 'strike', 'Chambers.', '', 'Russell', 'served', 'under', 'Robert', 'E.', 'Stripling', 'and', 'his', 'successor', 'Frank', 'S.', 'Tavenner', 'Jr..', '', 'He', 'helped', 'uncover', 'evidence', 'of', 'Soviet', 'spy', 'rings', 'and', 'leaks', 'of', 'atomic', 'secrets', 'and', 'materials', 'to', 'the', 'Soviet', 'Union.', '', 'In', '1952,', 'he', 'helped', 'try', 'to', 'find', 'Communist', 'influence', 'in', 'the', 'motion', 'picture', 'industry.\\nIn', 'January', '1954,', 'Russell', 'was', 'dismissed', 'by', 'committee', 'chair,', 'Representative', 'Harold', 'H.', 'Velde.', '', 'Russell', 'had', 'borrowed', '$300', 'from', 'actor', 'Edward', 'G.', 'Robinson.', '', 'In', '1956,', 'Russell', 'was', 'rehired', 'and', 'remained', 'with', 'HUAC', 'for', 'a', 'decade.\\n===Private', 'detective===\\nIn', '1966,', 'Russell', 'became', 'a', 'private', 'investigator.\\nTo', 'undermine', 'the', 'credibility', 'of', 'investigative', 'report', 'Jack', 'Anderson,', 'the', '', 'Richard', 'M.', 'Nixon', 'campaign', 'hired', 'Russell', '\"to', 'spy\"', 'on', 'him.', '', 'In', 'return', 'for', 'leads,', 'Anderson', 'gave', 'Russell', 'odd', 'jobs', 'for', 'the', '\"Washington', 'Merry-Go-Round,\"', 'enabling', 'Russell', 'to', 'send', 'information', 'back', 'to', 'the', 'campaign,', 'whose', 'director', 'of', 'security', 'was', 'James', 'W.', 'McCord\\nIn', '1971,', 'Russell', 'was', 'working', 'for', 'General', 'Security', 'Services,', 'Inc.', '(GSS),', 'a', 'security', 'guard', 'service', 'whose', 'clients', 'included', 'the', 'Watergate', 'offices.', '', 'After', 'the', 'Watergate', 'break-in', 'in', '1972,', 'James', 'W.', 'McCord', 'Jr.', '\"refused', 'to', 'discuss', 'Russell', 'under', 'any', 'circumstances', 'and...', 'would', 'not', 'discuss', 'Watergate', 'with', 'any', 'writer', 'who', 'so', 'much', 'as', 'expressed', 'interest', 'in', 'Lou', 'Russell.\"\\nFrom', 'June', '20', 'to', 'July', '2,', '1973,', 'Russell', 'was', 'working', 'for', 'a', 'detective', 'agency', 'that', 'was', 'helping', 'George', 'Herbert', 'Walker', 'Bush', '(then', 'chairman', 'of', 'the', 'Republican', 'National', 'Committee)', 'prepare', 'for', 'a', 'press', 'conference.\\nAccording', 'to', 'attorney', 'Gerald', 'Alch,', 'McCord', 'hired', '\"an', 'old', 'associate', 'of', 'his\"', '(Russell)', 'to', 'his', 'company', 'Security', 'International,', 'Inc.', '', 'Bob', 'Smith,', 'aide', 'and', 'office', 'manager', 'to', 'attorney', 'Bernard', 'Fensterwald', 'recounted', 'that', 'McCord', 'had', 'obtained', 'a', 'contract', 'to', 'provide', 'security', 'to', 'the', 'Republican', 'National', 'Committee.', 'Unable', 'to', 'cash', \"McCord's\", 'checks,', 'Russell', 'brought', 'some', 'dozen', 'checks', 'over', 'time', 'to', 'Fensterwald‚Äôs', 'office', 'at', 'the', '\"Committee', 'to', 'Investigate', 'Assassinations\"', 'or', 'CTIA', '(1520', '16th', 'Street', 'NW,', 'Washington', 'DC', '20036),', 'which', 'Fensterwald', 'would', 'cash.', '', 'During', 'the', 'Watergate', 'break-in,', 'Russell', 'was', 'checked', 'into', 'a', 'Howard', \"Johnson's\", 'Motel', 'across', 'from', 'Watergate.\\n==Personal', 'life', 'and', 'death==\\nAuthor', 'Jim', 'Hougan', 'characterized', 'Russell', 'as', 'an', 'alcoholic', 'and', 'womanizer.\\nRussell', 'died', 'age', '61', 'on', 'July', '2,', '1973,', 'in', 'Washington,', 'DC,', 'after', 'a', 'heart', 'attack.\\n==Legacy==\\nIn', '1984,', 'Jim', 'Hougan', 'wrote', 'a', 'book', 'called', 'Secret', 'Agenda:', 'Watergate,', 'Deep', 'Throat,', 'and', 'the', 'CIA', 'that', 'started', 'originally', 'about', 'Russell.\\n==See', 'also==\\nJ.', 'Edgar', 'Hoover\\nWilliam', 'C.', 'Sullivan\\nManhattan', 'Project\\nAlger', 'Hiss\\nWhittaker', 'Chambers\\n==References==\\n==External', 'links==\\nArchive.org:', '1947', 'HUAC', 'Testimony', 'of', 'Louis', 'J.', 'Russell', '(pp.', '296-305,', '341-342)\\nArchive.org:', '1950', 'HUAC', 'Testimony', 'of', 'Louis', 'J.', 'Russell', '(pp.', '902-907)\\nNixon', 'Library:', '', 'Guide', 'to', 'the', 'Congressional', 'Papers', '(1947-1950)\\nCIA:', '1952', 'HUAC', 'Testimony', 'of', 'Walter', 'Bedell', 'Smith]]\\n1973', 'deaths\\nFBI', 'agents\\nCatholic', 'University', 'of', 'America', 'alumni']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['louis', 'russell', 'circa', 'agent', 'federal', 'bureau', 'investigation', 'senior', 'investigator', 'house', 'american', 'activities', 'committee', 'huac', 'private', 'detective', 'background', 'louis', 'jam', 'russell', 'graduate', 'catholic', 'university', 'america', 'career', 'russell', 'join', 'agent', 'huac', 'russell', 'join', 'huac', 'investigator', 'robert', 'stripling', 'russell', 'testify', 'know', 'gerhart', 'eisler', 'hollywood', 'industry', 'people', 'testify', 'leon', 'josephson', 'alexander', 'koral', 'russell', 'huac', 'senior', 'investigator', 'hiss', 'chamber', 'case', 'memoir', 'crises', 'richard', 'nixon', 'recall', 'russell', 'restrain', 'hiss', 'hiss', 'strike', 'chamber', 'russell', 'serve', 'robert', 'stripling', 'successor', 'frank', 'tavenner', 'help', 'uncover', 'evidence', 'soviet', 'ring', 'leak', 'atomic', 'secrets', 'materials', 'soviet', 'union', 'help', 'communist', 'influence', 'motion', 'picture', 'industry', 'january', 'russell', 'dismiss', 'committee', 'chair', 'representative', 'harold', 'velde', 'russell', 'borrow', 'actor', 'edward', 'robinson', 'russell', 'rehired', 'remain', 'huac', 'decade', 'private', 'detective', 'russell', 'private', 'investigator', 'undermine', 'credibility', 'investigative', 'report', 'jack', 'anderson', 'richard', 'nixon', 'campaign', 'hire', 'russell', 'return', 'lead', 'anderson', 'give', 'russell', 'job', 'washington', 'merry', 'round', 'enable', 'russell', 'send', 'information', 'campaign', 'director', 'security', 'jam', 'mccord', 'russell', 'work', 'general', 'security', 'service', 'security', 'guard', 'service', 'clients', 'include', 'watergate', 'offices', 'watergate', 'break', 'jam', 'mccord', 'refuse', 'discuss', 'russell', 'circumstances', 'discuss', 'watergate', 'writer', 'express', 'russell', 'june', 'july', 'russell', 'work', 'detective', 'agency', 'help', 'george', 'herbert', 'walker', 'bush', 'chairman', 'republican', 'national', 'committee', 'prepare', 'press', 'conference', 'accord', 'attorney', 'gerald', 'alch', 'mccord', 'hire', 'associate', 'russell', 'company', 'security', 'international', 'smith', 'aide', 'office', 'manager', 'attorney', 'bernard', 'fensterwald', 'recount', 'mccord', 'obtain', 'contract', 'provide', 'security', 'republican', 'national', 'committee', 'unable', 'cash', 'mccord', 'check', 'russell', 'bring', 'dozen', 'check', 'time', 'fensterwald', 'office', 'committee', 'investigate', 'assassinations', 'ctia', 'street', 'washington', 'fensterwald', 'cash', 'watergate', 'break', 'russell', 'check', 'howard', 'johnson', 'motel', 'watergate', 'personal', 'life', 'death', 'author', 'hougan', 'characterize', 'russell', 'alcoholic', 'womanizer', 'russell', 'die', 'july', 'washington', 'heart', 'attack', 'legacy', 'hougan', 'write', 'book', 'call', 'secret', 'agenda', 'watergate', 'deep', 'throat', 'start', 'originally', 'russell', 'edgar', 'hoover', 'william', 'sullivan', 'manhattan', 'project', 'alger', 'hiss', 'whittaker', 'chamber', 'reference', 'external', 'link', 'archive', 'huac', 'testimony', 'louis', 'russell', 'archive', 'huac', 'testimony', 'louis', 'russell', 'nixon', 'library', 'guide', 'congressional', 'paper', 'huac', 'testimony', 'walter', 'bedell', 'smith', 'deaths', 'agents', 'catholic', 'university', 'america', 'alumni']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for word in docs[0].split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = list(map(lambda x: preprocess(x), docs))\n",
    "#processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accord\n",
      "1 activities\n",
      "2 actor\n",
      "3 agency\n",
      "4 agenda\n",
      "5 agent\n",
      "6 agents\n",
      "7 aide\n",
      "8 alch\n",
      "9 alcoholic\n",
      "10 alexander\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "count = []\n",
    "for i in bow_corpus:\n",
    "    for text in range(len(i)):\n",
    "        temp = \"{}\".format(dictionary[i[text][0]])\n",
    "        appearance = \"{}\".format(i[text][1])\n",
    "        words.append(temp)\n",
    "        count.append(appearance)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words['count'] = pd.Series(count)\n",
    "df_words['word'] = pd.Series(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = df_words.drop(['word number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accord</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>century</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>birth</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>serve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>return</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>originally</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>investigate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>guard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>die</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>deaths</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>death</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>book</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>turner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>condition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>molly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>jeff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>jacobs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>harrison</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>blake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>bean</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>baker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>silent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>plot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>release</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>feature</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>star</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>martha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>army</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9113</th>\n",
       "      <td>leave</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>text</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>align</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>style</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027</th>\n",
       "      <td>volleyball</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>service</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>lucia</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>research</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9409</th>\n",
       "      <td>league</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6092</th>\n",
       "      <td>football</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>liberal</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4194</th>\n",
       "      <td>award</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7683</th>\n",
       "      <td>general</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102</th>\n",
       "      <td>season</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>week</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>republic</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>railway</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>hull</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>song</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>drama</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>chinese</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>court</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>team</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>zhao</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>railway</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>television</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>club</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>june</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9407</th>\n",
       "      <td>volleyball</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10102 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word count\n",
       "0           accord     1\n",
       "6214       century     1\n",
       "6213         birth     1\n",
       "6212         write     1\n",
       "6211         serve     1\n",
       "6209        return     1\n",
       "6207    originally     1\n",
       "6205   investigate     1\n",
       "6204         guard     1\n",
       "6203           die     1\n",
       "6202        deaths     1\n",
       "6201         death     1\n",
       "6200          book     1\n",
       "6199        turner     1\n",
       "6215     condition     1\n",
       "6198         molly     1\n",
       "6196          jeff     1\n",
       "6195        jacobs     1\n",
       "6194      harrison     1\n",
       "6191         blake     1\n",
       "6189          bean     1\n",
       "6188         baker     1\n",
       "6185        silent     1\n",
       "6183          plot     1\n",
       "6181       release     1\n",
       "6180      language     1\n",
       "6178       feature     1\n",
       "6177          star     1\n",
       "6175         white     1\n",
       "6197        martha     1\n",
       "...            ...   ...\n",
       "5461          army     8\n",
       "9113         leave    80\n",
       "9133          text    81\n",
       "9115         align    81\n",
       "9117         style    81\n",
       "3027    volleyball     9\n",
       "5440       service     9\n",
       "3458         lucia     9\n",
       "4198      research     9\n",
       "9409        league     9\n",
       "6092      football     9\n",
       "773        liberal     9\n",
       "4194         award     9\n",
       "7683       general     9\n",
       "6102        season     9\n",
       "6129          week     9\n",
       "362       republic     9\n",
       "6588       railway     9\n",
       "2332          hull     9\n",
       "5174          song     9\n",
       "5302         drama     9\n",
       "7444       chinese     9\n",
       "8313         court     9\n",
       "4806          team     9\n",
       "6701          zhao     9\n",
       "6905       railway     9\n",
       "7018    television     9\n",
       "10061         club     9\n",
       "5427          june     9\n",
       "9407    volleyball     9\n",
       "\n",
       "[10102 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = df_words[['word','count']]\n",
    "df_words.sort_values(by=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "\n",
    "vectors = []\n",
    "for doc in corpus_tfidf:\n",
    "    vectors.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in vectors for item in sublist]\n",
    "vec = pd.DataFrame(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec['tfidf_score'] = vec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec['word'] = vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = vec.drop([0,1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = []\n",
    "three = []\n",
    "two = []\n",
    "one = []\n",
    "for row in vec['tfidf_score']:\n",
    "    if row > 0.110191: \n",
    "        four.append(row)\n",
    "    elif 0.110191 < value <= 0.059553:\n",
    "        three.append(row)\n",
    "    elif 0.032652 < value <= 0.059553:\n",
    "        two.append(row)\n",
    "    elif value <= 0.032652:\n",
    "        one.append(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_one:407533 , len_two:0 , len_three:0 , len_four:135844\n"
     ]
    }
   ],
   "source": [
    "print(\"len_one:\" + str(len(one)) + \" , len_two:\" + str(len(two)) \n",
    "      + \" , len_three:\" + str(len(three)) + \" , len_four:\" + str(len(four)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer()\n",
    "cv=CountVectorizer()\n",
    " \n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10102, 114203)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"tf_idf_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort ascending\n",
    "df_idf_sorted = df_idf.sort_values(by=['tf_idf_weights'], ascending=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count matrix\n",
    "count_vector=cv.transform(docs)\n",
    " \n",
    "# tf-idf scores\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>russell</th>\n",
       "      <td>0.674132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huac</th>\n",
       "      <td>0.300696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>watergate</th>\n",
       "      <td>0.215924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mccord</th>\n",
       "      <td>0.174262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiss</th>\n",
       "      <td>0.139410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fensterwald</th>\n",
       "      <td>0.112761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.111421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investigator</th>\n",
       "      <td>0.105638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.105441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nixon</th>\n",
       "      <td>0.092585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>committee</th>\n",
       "      <td>0.092380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbi</th>\n",
       "      <td>0.091555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testimony</th>\n",
       "      <td>0.085509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>0.083996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.081391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chambers</th>\n",
       "      <td>0.081111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detective</th>\n",
       "      <td>0.079229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0.076687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stripling</th>\n",
       "      <td>0.075174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hougan</th>\n",
       "      <td>0.075174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.074029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.063591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>checks</th>\n",
       "      <td>0.063306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.062107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>0.061742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cia</th>\n",
       "      <td>0.061723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spy</th>\n",
       "      <td>0.057411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private</th>\n",
       "      <td>0.056758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>0.054549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash</th>\n",
       "      <td>0.054074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fresca</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frereses</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fretworks</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freud</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freude</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freudeita</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friday</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frida</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frictional</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friction</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fricke</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frick</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friche</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friburguense</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fribourg</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frias</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friars</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friar</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frh</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frgs</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frfotbal</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frezza</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freysbush</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freyr</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freyi</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frey</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freusi√®re</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freundschaft</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freund</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ê≠åê≠Ñê≠ìê≠Éê≠ï</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114203 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tfidf\n",
       "russell       0.674132\n",
       "huac          0.300696\n",
       "watergate     0.215924\n",
       "mccord        0.174262\n",
       "hiss          0.139410\n",
       "fensterwald   0.112761\n",
       "to            0.111421\n",
       "investigator  0.105638\n",
       "security      0.105441\n",
       "nixon         0.092585\n",
       "committee     0.092380\n",
       "fbi           0.091555\n",
       "testimony     0.085509\n",
       "louis         0.083996\n",
       "the           0.081391\n",
       "chambers      0.081111\n",
       "detective     0.079229\n",
       "in            0.076687\n",
       "stripling     0.075174\n",
       "hougan        0.075174\n",
       "1973          0.074029\n",
       "of            0.063591\n",
       "checks        0.063306\n",
       "and           0.062107\n",
       "was           0.061742\n",
       "cia           0.061723\n",
       "spy           0.057411\n",
       "private       0.056758\n",
       "about         0.054549\n",
       "cash          0.054074\n",
       "...                ...\n",
       "fresca        0.000000\n",
       "frereses      0.000000\n",
       "fretworks     0.000000\n",
       "freud         0.000000\n",
       "freude        0.000000\n",
       "freudeita     0.000000\n",
       "friday        0.000000\n",
       "frida         0.000000\n",
       "frictional    0.000000\n",
       "friction      0.000000\n",
       "fricke        0.000000\n",
       "frick         0.000000\n",
       "friche        0.000000\n",
       "friburguense  0.000000\n",
       "fribourg      0.000000\n",
       "frias         0.000000\n",
       "friars        0.000000\n",
       "friar         0.000000\n",
       "frh           0.000000\n",
       "frgs          0.000000\n",
       "frfotbal      0.000000\n",
       "frezza        0.000000\n",
       "freysbush     0.000000\n",
       "freyr         0.000000\n",
       "freyi         0.000000\n",
       "frey          0.000000\n",
       "freusi√®re     0.000000\n",
       "freundschaft  0.000000\n",
       "freund        0.000000\n",
       "ê≠åê≠Ñê≠ìê≠Éê≠ï         0.000000\n",
       "\n",
       "[114203 rows x 1 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    " \n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    " \n",
    "#print the scores\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.674132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "count  114203.000000\n",
       "mean        0.000090\n",
       "std         0.002958\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         0.674132"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_difficulty = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_difficulty = list(words_difficulty.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_difficulty = words_difficulty[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#four = {k:v for k,v in words_difficulty.items() if v > 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = []\n",
    "three = []\n",
    "two = []\n",
    "one = []\n",
    "for i in words_difficulty.items():\n",
    "    if value > 0.110191: \n",
    "        four.append((key,value))\n",
    "    elif 0.110191 >= value > 0.059553:\n",
    "        three.append((key,value))\n",
    "    elif 0.059553 >= value > 0.032652:\n",
    "        two.append((key,value))\n",
    "    elif value <= 0.032652:\n",
    "        one.append((key,value))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_one:114201 , len_two:1 , len_three:1 , len_four:0\n"
     ]
    }
   ],
   "source": [
    "print(\"len_one:\" + str(len(one)) + \" , len_two:\" + str(len(two)) \n",
    "      + \" , len_three:\" + str(len(three)) + \" , len_four:\" + str(len(four)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    \"\"\" \n",
    "    Takes in a corpus and counts how many words are part of a list of words in the 75th+ percentile of sample_text\n",
    "    , counts how many words are part of a list of words in the 50-75th+ percentile of sample_text\n",
    "    , counts how many words are part of a list of words in the 25-50th+ percentile of sample_text\n",
    "    , counts how many words are part of a list of words in the 0-25th percentile of sample_text\n",
    "    \"\"\"\n",
    "    for i in ___: \n",
    "        if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
