{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.set_lang(\"en\")\n",
    "statistics = wikipedia.search(\"statistics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = wikipedia.page(\"Statistics\")\n",
    "#print(statistics.title)\n",
    "#print(statistics.url)\n",
    "#print(statistics.content)\n",
    "#print(statistics.links[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Statistics is a branch of mathematics working with data collection, organization, analysis, interpretation and presentation.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.summary(\"Statistics\", sentences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install wikipedia-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install wiki-dump-reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiki_dump_reader import Cleaner, iterate\n",
    "\n",
    "corpus = []\n",
    "cleaner = Cleaner()\n",
    "for title, text in iterate('data/enwiki-latest-pages-articles.xml'):\n",
    "    text = cleaner.clean_text(text)\n",
    "    cleaned_text, links = cleaner.build_links(text)\n",
    "    corpus.append(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29316"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = []\n",
    "for i in corpus:\n",
    "    if len(i) > 100:\n",
    "        long_text.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = long_text[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complic'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "PorterStemmer().stem('complications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sherzyang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Louis', 'J.', 'Russell', '(circa', '1912–1973)', 'was', 'an', 'agent', 'of', 'the', 'Federal', 'Bureau', 'of', 'Investigation', '(FBI),', 'senior', 'investigator', 'of', 'the', 'House', 'Un-American', 'Activities', 'Committee', '(HUAC),', 'and', 'private', 'detective.\\n==Background==\\nLouis', 'James', 'Russell', 'graduated', 'from', 'the', 'Catholic', 'University', 'of', 'America.\\n==Career==\\nIn', '1935,', 'Russell', 'joined', 'the', 'FBI', 'as', 'an', 'agent.\\n===HUAC===\\nIn', '1945,', 'Russell', 'joined', 'HUAC', 'as', 'an', 'investigator.', '', 'Robert', 'E.', 'Stripling', 'has', 'Russell', 'testify', 'on', 'what', 'he', 'knew', 'about', 'Gerhart', 'Eisler', 'and', 'Hollywood', 'industry', 'people.', '', 'He', 'also', 'testified', 'about', 'Leon', 'Josephson', 'and', 'Alexander', 'Koral.', '', 'By', '1948,', 'Russell', 'was', 'a', 'HUAC', 'senior', 'investigator', 'in', 'the', 'Hiss-Chambers', 'case.', '', 'In', 'his', 'memoir', 'Six', 'Crises,', 'Richard', 'Nixon', 'recalled', 'that', 'Russell', 'restrained', 'Hiss', 'when', 'it', 'seemed', 'Hiss', 'was', 'about', 'to', 'strike', 'Chambers.', '', 'Russell', 'served', 'under', 'Robert', 'E.', 'Stripling', 'and', 'his', 'successor', 'Frank', 'S.', 'Tavenner', 'Jr..', '', 'He', 'helped', 'uncover', 'evidence', 'of', 'Soviet', 'spy', 'rings', 'and', 'leaks', 'of', 'atomic', 'secrets', 'and', 'materials', 'to', 'the', 'Soviet', 'Union.', '', 'In', '1952,', 'he', 'helped', 'try', 'to', 'find', 'Communist', 'influence', 'in', 'the', 'motion', 'picture', 'industry.\\nIn', 'January', '1954,', 'Russell', 'was', 'dismissed', 'by', 'committee', 'chair,', 'Representative', 'Harold', 'H.', 'Velde.', '', 'Russell', 'had', 'borrowed', '$300', 'from', 'actor', 'Edward', 'G.', 'Robinson.', '', 'In', '1956,', 'Russell', 'was', 'rehired', 'and', 'remained', 'with', 'HUAC', 'for', 'a', 'decade.\\n===Private', 'detective===\\nIn', '1966,', 'Russell', 'became', 'a', 'private', 'investigator.\\nTo', 'undermine', 'the', 'credibility', 'of', 'investigative', 'report', 'Jack', 'Anderson,', 'the', '', 'Richard', 'M.', 'Nixon', 'campaign', 'hired', 'Russell', '\"to', 'spy\"', 'on', 'him.', '', 'In', 'return', 'for', 'leads,', 'Anderson', 'gave', 'Russell', 'odd', 'jobs', 'for', 'the', '\"Washington', 'Merry-Go-Round,\"', 'enabling', 'Russell', 'to', 'send', 'information', 'back', 'to', 'the', 'campaign,', 'whose', 'director', 'of', 'security', 'was', 'James', 'W.', 'McCord\\nIn', '1971,', 'Russell', 'was', 'working', 'for', 'General', 'Security', 'Services,', 'Inc.', '(GSS),', 'a', 'security', 'guard', 'service', 'whose', 'clients', 'included', 'the', 'Watergate', 'offices.', '', 'After', 'the', 'Watergate', 'break-in', 'in', '1972,', 'James', 'W.', 'McCord', 'Jr.', '\"refused', 'to', 'discuss', 'Russell', 'under', 'any', 'circumstances', 'and...', 'would', 'not', 'discuss', 'Watergate', 'with', 'any', 'writer', 'who', 'so', 'much', 'as', 'expressed', 'interest', 'in', 'Lou', 'Russell.\"\\nFrom', 'June', '20', 'to', 'July', '2,', '1973,', 'Russell', 'was', 'working', 'for', 'a', 'detective', 'agency', 'that', 'was', 'helping', 'George', 'Herbert', 'Walker', 'Bush', '(then', 'chairman', 'of', 'the', 'Republican', 'National', 'Committee)', 'prepare', 'for', 'a', 'press', 'conference.\\nAccording', 'to', 'attorney', 'Gerald', 'Alch,', 'McCord', 'hired', '\"an', 'old', 'associate', 'of', 'his\"', '(Russell)', 'to', 'his', 'company', 'Security', 'International,', 'Inc.', '', 'Bob', 'Smith,', 'aide', 'and', 'office', 'manager', 'to', 'attorney', 'Bernard', 'Fensterwald', 'recounted', 'that', 'McCord', 'had', 'obtained', 'a', 'contract', 'to', 'provide', 'security', 'to', 'the', 'Republican', 'National', 'Committee.', 'Unable', 'to', 'cash', \"McCord's\", 'checks,', 'Russell', 'brought', 'some', 'dozen', 'checks', 'over', 'time', 'to', 'Fensterwald’s', 'office', 'at', 'the', '\"Committee', 'to', 'Investigate', 'Assassinations\"', 'or', 'CTIA', '(1520', '16th', 'Street', 'NW,', 'Washington', 'DC', '20036),', 'which', 'Fensterwald', 'would', 'cash.', '', 'During', 'the', 'Watergate', 'break-in,', 'Russell', 'was', 'checked', 'into', 'a', 'Howard', \"Johnson's\", 'Motel', 'across', 'from', 'Watergate.\\n==Personal', 'life', 'and', 'death==\\nAuthor', 'Jim', 'Hougan', 'characterized', 'Russell', 'as', 'an', 'alcoholic', 'and', 'womanizer.\\nRussell', 'died', 'age', '61', 'on', 'July', '2,', '1973,', 'in', 'Washington,', 'DC,', 'after', 'a', 'heart', 'attack.\\n==Legacy==\\nIn', '1984,', 'Jim', 'Hougan', 'wrote', 'a', 'book', 'called', 'Secret', 'Agenda:', 'Watergate,', 'Deep', 'Throat,', 'and', 'the', 'CIA', 'that', 'started', 'originally', 'about', 'Russell.\\n==See', 'also==\\nJ.', 'Edgar', 'Hoover\\nWilliam', 'C.', 'Sullivan\\nManhattan', 'Project\\nAlger', 'Hiss\\nWhittaker', 'Chambers\\n==References==\\n==External', 'links==\\nArchive.org:', '1947', 'HUAC', 'Testimony', 'of', 'Louis', 'J.', 'Russell', '(pp.', '296-305,', '341-342)\\nArchive.org:', '1950', 'HUAC', 'Testimony', 'of', 'Louis', 'J.', 'Russell', '(pp.', '902-907)\\nNixon', 'Library:', '', 'Guide', 'to', 'the', 'Congressional', 'Papers', '(1947-1950)\\nCIA:', '1952', 'HUAC', 'Testimony', 'of', 'Walter', 'Bedell', 'Smith]]\\n1973', 'deaths\\nFBI', 'agents\\nCatholic', 'University', 'of', 'America', 'alumni']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['louis', 'russell', 'circa', 'agent', 'federal', 'bureau', 'investigation', 'senior', 'investigator', 'house', 'american', 'activities', 'committee', 'huac', 'private', 'detective', 'background', 'louis', 'jam', 'russell', 'graduate', 'catholic', 'university', 'america', 'career', 'russell', 'join', 'agent', 'huac', 'russell', 'join', 'huac', 'investigator', 'robert', 'stripling', 'russell', 'testify', 'know', 'gerhart', 'eisler', 'hollywood', 'industry', 'people', 'testify', 'leon', 'josephson', 'alexander', 'koral', 'russell', 'huac', 'senior', 'investigator', 'hiss', 'chamber', 'case', 'memoir', 'crises', 'richard', 'nixon', 'recall', 'russell', 'restrain', 'hiss', 'hiss', 'strike', 'chamber', 'russell', 'serve', 'robert', 'stripling', 'successor', 'frank', 'tavenner', 'help', 'uncover', 'evidence', 'soviet', 'ring', 'leak', 'atomic', 'secrets', 'materials', 'soviet', 'union', 'help', 'communist', 'influence', 'motion', 'picture', 'industry', 'january', 'russell', 'dismiss', 'committee', 'chair', 'representative', 'harold', 'velde', 'russell', 'borrow', 'actor', 'edward', 'robinson', 'russell', 'rehired', 'remain', 'huac', 'decade', 'private', 'detective', 'russell', 'private', 'investigator', 'undermine', 'credibility', 'investigative', 'report', 'jack', 'anderson', 'richard', 'nixon', 'campaign', 'hire', 'russell', 'return', 'lead', 'anderson', 'give', 'russell', 'job', 'washington', 'merry', 'round', 'enable', 'russell', 'send', 'information', 'campaign', 'director', 'security', 'jam', 'mccord', 'russell', 'work', 'general', 'security', 'service', 'security', 'guard', 'service', 'clients', 'include', 'watergate', 'offices', 'watergate', 'break', 'jam', 'mccord', 'refuse', 'discuss', 'russell', 'circumstances', 'discuss', 'watergate', 'writer', 'express', 'russell', 'june', 'july', 'russell', 'work', 'detective', 'agency', 'help', 'george', 'herbert', 'walker', 'bush', 'chairman', 'republican', 'national', 'committee', 'prepare', 'press', 'conference', 'accord', 'attorney', 'gerald', 'alch', 'mccord', 'hire', 'associate', 'russell', 'company', 'security', 'international', 'smith', 'aide', 'office', 'manager', 'attorney', 'bernard', 'fensterwald', 'recount', 'mccord', 'obtain', 'contract', 'provide', 'security', 'republican', 'national', 'committee', 'unable', 'cash', 'mccord', 'check', 'russell', 'bring', 'dozen', 'check', 'time', 'fensterwald', 'office', 'committee', 'investigate', 'assassinations', 'ctia', 'street', 'washington', 'fensterwald', 'cash', 'watergate', 'break', 'russell', 'check', 'howard', 'johnson', 'motel', 'watergate', 'personal', 'life', 'death', 'author', 'hougan', 'characterize', 'russell', 'alcoholic', 'womanizer', 'russell', 'die', 'july', 'washington', 'heart', 'attack', 'legacy', 'hougan', 'write', 'book', 'call', 'secret', 'agenda', 'watergate', 'deep', 'throat', 'start', 'originally', 'russell', 'edgar', 'hoover', 'william', 'sullivan', 'manhattan', 'project', 'alger', 'hiss', 'whittaker', 'chamber', 'reference', 'external', 'link', 'archive', 'huac', 'testimony', 'louis', 'russell', 'archive', 'huac', 'testimony', 'louis', 'russell', 'nixon', 'library', 'guide', 'congressional', 'paper', 'huac', 'testimony', 'walter', 'bedell', 'smith', 'deaths', 'agents', 'catholic', 'university', 'america', 'alumni']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for word in docs[0].split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = list(map(lambda x: preprocess(x), docs))\n",
    "#processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accord\n",
      "1 activities\n",
      "2 actor\n",
      "3 agency\n",
      "4 agenda\n",
      "5 agent\n",
      "6 agents\n",
      "7 aide\n",
      "8 alch\n",
      "9 alcoholic\n",
      "10 alexander\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(30, 1),\n",
       " (76, 1),\n",
       " (102, 2),\n",
       " (129, 1),\n",
       " (185, 2),\n",
       " (273, 2),\n",
       " (346, 1),\n",
       " (348, 1),\n",
       " (400, 1),\n",
       " (464, 1),\n",
       " (476, 2),\n",
       " (499, 2),\n",
       " (547, 2),\n",
       " (563, 1),\n",
       " (565, 1),\n",
       " (591, 12),\n",
       " (640, 2),\n",
       " (691, 2),\n",
       " (706, 1),\n",
       " (840, 1),\n",
       " (867, 1),\n",
       " (871, 2),\n",
       " (1057, 1),\n",
       " (1087, 1),\n",
       " (1133, 1),\n",
       " (1276, 1),\n",
       " (1344, 1),\n",
       " (1428, 5),\n",
       " (1518, 1),\n",
       " (1695, 1),\n",
       " (1742, 2),\n",
       " (1777, 1),\n",
       " (1997, 2),\n",
       " (2010, 1),\n",
       " (2165, 1),\n",
       " (2174, 1),\n",
       " (2188, 1),\n",
       " (2204, 2),\n",
       " (2278, 1),\n",
       " (2380, 1),\n",
       " (2444, 1),\n",
       " (2457, 1),\n",
       " (2596, 1),\n",
       " (2669, 2),\n",
       " (2813, 3),\n",
       " (2992, 1),\n",
       " (3376, 1),\n",
       " (3437, 1),\n",
       " (3438, 1),\n",
       " (3520, 1),\n",
       " (3551, 1),\n",
       " (4080, 2),\n",
       " (4306, 1),\n",
       " (4596, 2),\n",
       " (4634, 1),\n",
       " (4795, 1),\n",
       " (4904, 1),\n",
       " (5288, 1),\n",
       " (5576, 1),\n",
       " (5743, 1),\n",
       " (6069, 5)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 30 (\"catholic\") appears 1 time.\n",
      "Word 76 (\"house\") appears 1 time.\n",
      "Word 102 (\"louis\") appears 2 time.\n",
      "Word 129 (\"return\") appears 1 time.\n",
      "Word 185 (\"century\") appears 2 time.\n",
      "Word 273 (\"sell\") appears 2 time.\n",
      "Word 346 (\"august\") appears 1 time.\n",
      "Word 348 (\"couple\") appears 1 time.\n",
      "Word 400 (\"land\") appears 1 time.\n",
      "Word 464 (\"year\") appears 1 time.\n",
      "Word 476 (\"count\") appears 2 time.\n",
      "Word 499 (\"mention\") appears 2 time.\n",
      "Word 547 (\"city\") appears 2 time.\n",
      "Word 563 (\"later\") appears 1 time.\n",
      "Word 565 (\"member\") appears 1 time.\n",
      "Word 591 (\"castle\") appears 12 time.\n",
      "Word 640 (\"take\") appears 2 time.\n",
      "Word 691 (\"build\") appears 2 time.\n",
      "Word 706 (\"structure\") appears 1 time.\n",
      "Word 840 (\"history\") appears 1 time.\n",
      "Word 867 (\"pass\") appears 1 time.\n",
      "Word 871 (\"present\") appears 2 time.\n",
      "Word 1057 (\"sign\") appears 1 time.\n",
      "Word 1087 (\"buy\") appears 1 time.\n",
      "Word 1133 (\"own\") appears 1 time.\n",
      "Word 1276 (\"peace\") appears 1 time.\n",
      "Word 1344 (\"style\") appears 1 time.\n",
      "Word 1428 (\"family\") appears 5 time.\n",
      "Word 1518 (\"residential\") appears 1 time.\n",
      "Word 1695 (\"surround\") appears 1 time.\n",
      "Word 1742 (\"maria\") appears 2 time.\n",
      "Word 1777 (\"wed\") appears 1 time.\n",
      "Word 1997 (\"baroque\") appears 2 time.\n",
      "Word 2010 (\"duke\") appears 1 time.\n",
      "Word 2165 (\"agreement\") appears 1 time.\n",
      "Word 2174 (\"court\") appears 1 time.\n",
      "Word 2188 (\"lease\") appears 1 time.\n",
      "Word 2204 (\"purchase\") appears 2 time.\n",
      "Word 2278 (\"princess\") appears 1 time.\n",
      "Word 2380 (\"roof\") appears 1 time.\n",
      "Word 2444 (\"establishments\") appears 1 time.\n",
      "Word 2457 (\"palm\") appears 1 time.\n",
      "Word 2596 (\"occupy\") appears 1 time.\n",
      "Word 2669 (\"karl\") appears 2 time.\n",
      "Word 2813 (\"prince\") appears 3 time.\n",
      "Word 2992 (\"abbey\") appears 1 time.\n",
      "Word 3376 (\"friedrich\") appears 1 time.\n",
      "Word 3437 (\"ceremony\") appears 1 time.\n",
      "Word 3438 (\"citizens\") appears 1 time.\n",
      "Word 3520 (\"medieval\") appears 1 time.\n",
      "Word 3551 (\"birthplace\") appears 1 time.\n",
      "Word 4080 (\"baron\") appears 2 time.\n",
      "Word 4306 (\"wilhelm\") appears 1 time.\n",
      "Word 4596 (\"anna\") appears 2 time.\n",
      "Word 4634 (\"johannes\") appears 1 time.\n",
      "Word 4795 (\"monastery\") appears 1 time.\n",
      "Word 4904 (\"residency\") appears 1 time.\n",
      "Word 5288 (\"fortress\") appears 1 time.\n",
      "Word 5576 (\"consecrate\") appears 1 time.\n",
      "Word 5743 (\"residences\") appears 1 time.\n",
      "Word 6069 (\"bavaria\") appears 5 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.01975597996885863),\n",
      " (1, 0.024616656549925547),\n",
      " (2, 0.023401312152280383),\n",
      " (3, 0.026894951800343018),\n",
      " (4, 0.038157674569633836),\n",
      " (5, 0.05975186436166865),\n",
      " (6, 0.03476452978572037),\n",
      " (7, 0.025735060986434567),\n",
      " (8, 0.01703969015442193),\n",
      " (9, 0.040557447075180886),\n",
      " (10, 0.00999444844456913),\n",
      " (11, 0.06295709016576807),\n",
      " (12, 0.05614020383685628),\n",
      " (13, 0.020173913580201028),\n",
      " (14, 0.024027435910886418),\n",
      " (15, 0.05640280844456067),\n",
      " (16, 0.020261127017247738),\n",
      " (17, 0.01941092786553807),\n",
      " (18, 0.03419514540509581),\n",
      " (19, 0.016519882940793287),\n",
      " (20, 0.03609759256050745),\n",
      " (21, 0.04468383240504221),\n",
      " (22, 0.02114989910355971),\n",
      " (23, 0.031035822994742775),\n",
      " (24, 0.03456864291406418),\n",
      " (25, 0.016510497213274133),\n",
      " (26, 0.045454940506187015),\n",
      " (27, 0.011629627959190512),\n",
      " (28, 0.02163827865884029),\n",
      " (29, 0.06993411628296306),\n",
      " (30, 0.050379369466494954),\n",
      " (31, 0.025110030028668857),\n",
      " (32, 0.02535225297789494),\n",
      " (33, 0.08068485540102906),\n",
      " (34, 0.03351165632684497),\n",
      " (35, 0.1000570195092908),\n",
      " (36, 0.038157674569633836),\n",
      " (37, 0.03496705814148153),\n",
      " (38, 0.03419514540509581),\n",
      " (39, 0.11013391784308371),\n",
      " (40, 0.030826186947081773),\n",
      " (41, 0.015487317498822413),\n",
      " (42, 0.02224316991568198),\n",
      " (43, 0.037186784154760656),\n",
      " (44, 0.024366959903949947),\n",
      " (45, 0.016978522237747457),\n",
      " (46, 0.013674619763149187),\n",
      " (47, 0.0322109731128279),\n",
      " (48, 0.027815850171707932),\n",
      " (49, 0.10258543621528741),\n",
      " (50, 0.016146670078130483),\n",
      " (51, 0.018090069414376752),\n",
      " (52, 0.05614020383685628),\n",
      " (53, 0.031594549006193795),\n",
      " (54, 0.03661739977413609),\n",
      " (55, 0.03609759256050745),\n",
      " (56, 0.024160938993668318),\n",
      " (57, 0.03125308382242688),\n",
      " (58, 0.025913403016296292),\n",
      " (59, 0.025913403016296292),\n",
      " (60, 0.007313217920229384),\n",
      " (61, 0.024027435910886418),\n",
      " (62, 0.02429749383825452),\n",
      " (63, 0.016389805950110622),\n",
      " (64, 0.018900017175276784),\n",
      " (65, 0.03437897573514797),\n",
      " (66, 0.016662467616907532),\n",
      " (67, 0.018114553113963018),\n",
      " (68, 0.026789214272990226),\n",
      " (69, 0.02503142344275376),\n",
      " (70, 0.03072406455710836),\n",
      " (71, 0.024992504644931378),\n",
      " (72, 0.06016174498961119),\n",
      " (73, 0.03042777171966443),\n",
      " (74, 0.05479078856558996),\n",
      " (75, 0.03042777171966443),\n",
      " (76, 0.013912659792085747),\n",
      " (77, 0.02898018759120844),\n",
      " (78, 0.010202846785958309),\n",
      " (79, 0.045942682867254725),\n",
      " (80, 0.022861723416149747),\n",
      " (81, 0.020988973162009466),\n",
      " (82, 0.014066399988685495),\n",
      " (83, 0.027692670254337585),\n",
      " (84, 0.028201404222280336),\n",
      " (85, 0.13678058162038323),\n",
      " (86, 0.024726949178022945),\n",
      " (87, 0.05907522790986951),\n",
      " (88, 0.01462769160650497),\n",
      " (89, 0.03517669418914253),\n",
      " (90, 0.026737039143641065),\n",
      " (91, 0.03266982832225206),\n",
      " (92, 0.0305248832208081),\n",
      " (93, 0.014085117542390604),\n",
      " (94, 0.011853336725263256),\n",
      " (95, 0.017101490853876748),\n",
      " (96, 0.038157674569633836),\n",
      " (97, 0.02807010191842814),\n",
      " (98, 0.03367533819146716),\n",
      " (99, 0.024437243236220346),\n",
      " (100, 0.01301261314987337),\n",
      " (101, 0.006751152394225734),\n",
      " (102, 0.10347326360650128),\n",
      " (103, 0.02358235674465693),\n",
      " (104, 0.032613868291214175),\n",
      " (105, 0.029788718743787614),\n",
      " (106, 0.03561941627728379),\n",
      " (107, 0.02406053302788058),\n",
      " (108, 0.02109745570085619),\n",
      " (109, 0.023283593775138473),\n",
      " (110, 0.037969113049546414),\n",
      " (111, 0.02628690052526467),\n",
      " (112, 0.02029637204182059),\n",
      " (113, 0.024764170571561384),\n",
      " (114, 0.006313532667394319),\n",
      " (115, 0.018507471884190718),\n",
      " (116, 0.020890552248354),\n",
      " (117, 0.026948530763404935),\n",
      " (118, 0.018789127414454904),\n",
      " (119, 0.06810293371989218),\n",
      " (120, 0.01933521057390603),\n",
      " (121, 0.018872101169632602),\n",
      " (122, 0.0322109731128279),\n",
      " (123, 0.03585372137997359),\n",
      " (124, 0.02739539428279498),\n",
      " (125, 0.01754182413252115),\n",
      " (126, 0.019580963037509166),\n",
      " (127, 0.025647847549387853),\n",
      " (128, 0.052382628513324425),\n",
      " (129, 0.016838186588840346),\n",
      " (130, 0.04468383240504221),\n",
      " (131, 0.028830829453386594),\n",
      " (132, 0.04162593311215569),\n",
      " (133, 0.03247652857973633),\n",
      " (134, 0.018872101169632602),\n",
      " (135, 0.8628314768849076),\n",
      " (136, 0.03033218545106197),\n",
      " (137, 0.03661739977413609),\n",
      " (138, 0.13002305556848606),\n",
      " (139, 0.02294374778485948),\n",
      " (140, 0.04073498420015072),\n",
      " (141, 0.013317940750139265),\n",
      " (142, 0.035150709406523706),\n",
      " (143, 0.049985009289862756),\n",
      " (144, 0.05538534050867517),\n",
      " (145, 0.015009141215598761),\n",
      " (146, 0.020812966556077846),\n",
      " (147, 0.026384041110081736),\n",
      " (148, 0.030238104540748212),\n",
      " (149, 0.033843631414355466),\n",
      " (150, 0.07323479954827218),\n",
      " (151, 0.11247963309249011),\n",
      " (152, 0.011291385874685545),\n",
      " (153, 0.028685114562719667),\n",
      " (154, 0.03749321103083003),\n",
      " (155, 0.020475785355525786),\n",
      " (156, 0.023005120170192385),\n",
      " (157, 0.029534466997067407),\n",
      " (158, 0.026004611113697212),\n",
      " (159, 0.06344969731067912),\n",
      " (160, 0.018761723630910918),\n",
      " (161, 0.021898101588798253),\n",
      " (162, 0.015075153095400255),\n",
      " (163, 0.022391908246029373)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer()\n",
    "cv=CountVectorizer()\n",
    " \n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10102, 114203)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"tf_idf_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort ascending\n",
    "df_idf_sorted = df_idf.sort_values(by=['tf_idf_weights'], ascending=False)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_difficulty = df_idf_sorted.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_difficulty = list(words_difficulty.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_difficulty = words_difficulty[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#four = {k:v for k,v in words_difficulty.items() if v > 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "four = []\n",
    "three = []\n",
    "two = []\n",
    "one = []\n",
    "for key, value in words_difficulty.items():\n",
    "    if value > 2.704748: \n",
    "        four.append((key,value))\n",
    "    elif 2.704748 >= value > 2.612536:\n",
    "        three.append((key,value))\n",
    "    elif 2.612536 >= value > 2:\n",
    "        two.append((key,value))\n",
    "    elif value <= 2:\n",
    "        one.append((key,value))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_one:16 , len_two:17 , len_three:3 , len_four:114167\n"
     ]
    }
   ],
   "source": [
    "print(\"len_one:\" + str(len(one)) + \" , len_two:\" + str(len(two)) \n",
    "      + \" , len_three:\" + str(len(three)) + \" , len_four:\" + str(len(four)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    \"\"\" \n",
    "    Takes in a corpus and counts how many words are part of a list of words in the 75th+ percentile of sample_text\n",
    "    , counts how many words are part of a list of words in the 50-75th+ percentile of sample_text\n",
    "    , counts how many words are part of a list of words in the 25-50th+ percentile of sample_text\n",
    "    , counts how many words are part of a list of words in the 0-25th percentile of sample_text\n",
    "    \"\"\"\n",
    "    for i in ___: \n",
    "        if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
