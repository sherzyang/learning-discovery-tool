{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import wikipediaapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Art and culture\n",
    "Geography and places\n",
    "Health and fitness\n",
    "History and events\n",
    "Mathematics and abstractions\n",
    "Natural sciences and nature\n",
    "People and self\n",
    "Philosophy and thinking\n",
    "Religion and spirituality\n",
    "Social sciences and society\n",
    "Technology and applied sciences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drink_list = wikipedia.search(\"drink\", results=1000)\n",
    "# food_list = wikipedia.search(\"food\", results=1000)\n",
    "# ancient_list = wikipedia.search(\"ancient\", results=1000)\n",
    "# transportation_list = wikipedia.search(\"transportation\", results=1000)\n",
    "# shows_list = wikipedia.search(\"shows\", results=1000)\n",
    "# music_list = wikipedia.search(\"music\", results=1000)\n",
    "# actors_list = wikipedia.search(\"actors\", results=1000)\n",
    "# movies_list = wikipedia.search(\"movies\", results=1000)\n",
    "# finance_list = wikipedia.search(\"finance\", results=1000)\n",
    "# #\n",
    "# language_list = wikipedia.search(\"language\", results=1000)\n",
    "# nature_list = wikipedia.search(\"nature\", results=1000)\n",
    "# environment_list = wikipedia.search(\"environment\", results=1000)\n",
    "# history_list = wikipedia.search(\"history\", results=1000)\n",
    "# econ_list = wikipedia.search(\"economics\", results=1000)\n",
    "# nature_list = wikipedia.search(\"nature\", results=1000)\n",
    "# lit_list = wikipedia.search(\"literature\", results=1000)\n",
    "# psych_list = wikipedia.search(\"psychology\", results=1000)\n",
    "# behavioral = wikipedia.search(\"behavioral\", results=1000)\n",
    "# global_list = wikipedia.search(\"global\", results=1000)\n",
    "# cities_list = wikipedia.search(\"cities\", results=1000)\n",
    "# anthropology = wikipedia.search(\"anthropology\", results=1000)\n",
    "# #\n",
    "# art_culture = wikipedia.search(\"art culture\", results=1000)\n",
    "# geo_places = wikipedia.search(\"geography places\", results=1000)\n",
    "# health_fit = wikipedia.search(\"health fitness\", results=1000)\n",
    "# history_events = wikipedia.search(\"history events\", results=1000)\n",
    "# math = wikipedia.search(\"mathematics abstractions\", results=1000)\n",
    "# natural_science = wikipedia.search(\"natural sciences nature\", results=1000)\n",
    "# people_self = wikipedia.search(\"people self\", results=1000)\n",
    "# philosophy = wikipedia.search(\"philosophy thinking\", results=1000)\n",
    "# religion = wikipedia.search(\"religion spirituality\", results=1000)\n",
    "# social_society = wikipedia.search(\"social sciences society\", results=1000)\n",
    "# tech = wikipedia.search(\"technology applied sciences\", results=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_articles = (art_culture + geo_places + health_fit + history_events + \n",
    "#                 math + natural_science + people_self + philosophy + religion\n",
    "#                 + social_society + tech + anthropology + cities_list + global_list\n",
    "#                 + behavioral + psych_list + lit_list + nature_list + econ_list \n",
    "#                 + history_list + environment_list + nature_list + language_list\n",
    "#                 + finance_list + movies_list + actors_list + music_list + shows_list\n",
    "#                 + transportation_list + ancient_list + food_list + drink_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_articles_unique = list(set(all_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('data/unique_articles.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_articles_unique, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_articles():\n",
    "    docs2_long_text = []\n",
    "    wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI) \n",
    "    for i in range(len(all_articles_unique)):\n",
    "        temp = wiki_wiki.page(all_articles_unique[i])\n",
    "        if len(temp.text) > 300:\n",
    "            docs2_long_text.append(temp.text)\n",
    "        else: \n",
    "            continue\n",
    "    return docs2_long_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_collected_articles = collect_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('data/collected_articles.pkl', 'wb') as f:\n",
    "#     pickle.dump(all_collected_articles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data/collected_articles.pkl\", \"rb\") as input_file:\n",
    "    collected_articles = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_corpus2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus2['content'] = pd.Series(collected_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textstat in /Users/sherzyang/anaconda3/lib/python3.6/site-packages (0.5.6)\r\n",
      "Requirement already satisfied: pyphen in /Users/sherzyang/anaconda3/lib/python3.6/site-packages (from textstat) (0.9.5)\r\n",
      "Requirement already satisfied: repoze.lru in /Users/sherzyang/anaconda3/lib/python3.6/site-packages (from textstat) (0.7)\r\n"
     ]
    }
   ],
   "source": [
    "#! pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity = [textstat.flesch_kincaid_grade(doc) for doc in collected_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus2['score'] = pd.Series(complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('data/df_corpus2.pkl', 'wb') as f:\n",
    "#     pickle.dump(df_corpus2, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
