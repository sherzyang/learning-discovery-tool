{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files and Vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import textstat\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import cosine, cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data/df_corpus2.pkl\", \"rb\") as input_file:\n",
    "    df_corpus2 = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data/df_best_category.pkl\", \"rb\") as input_file:\n",
    "    df_best_category = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r\"data/dictionary.pkl\", \"rb\") as input_file: \n",
    "    dictionary = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r\"data/lda_model_1.pkl\", \"rb\") as input_file:\n",
    "    lda_model_1 = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data/df_best_category.pkl\", 'rb') as input_file:\n",
    "      df_best_category = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>article_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  article_index\n",
       "0         2              0\n",
       "1         5              1\n",
       "2         5              2\n",
       "3         4              3\n",
       "4         6              4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_category.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "import operator\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "def give_harder_level(text):\n",
    "    \"\"\"\n",
    "    Takes in text and returns a harder level read\n",
    "    \"\"\"\n",
    "    unseen_document = str(text)\n",
    "    dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "    bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "    text_topics = lda_model_1[bow_vector]\n",
    "    topic_group = max(text_topics,key=itemgetter(1))[0]\n",
    "    \n",
    "    category_df = df_best_category.loc[df_best_category['category'] == topic_group] \n",
    "    \n",
    "    ##find all the articles that are easier than this article \n",
    "#     all_harder_text = []\n",
    "#     input_score = textstat.flesch_kincaid_grade(text)\n",
    "#     for i in range(len(df_corpus2['score'])):\n",
    "#         if df_corpus2['score'][i] > input_score:\n",
    "#             all_harder_text.append(df_corpus2['content'][i])\n",
    "    \n",
    "    all_harder_text = []\n",
    "    \n",
    "    for i in category_df['article_index']: \n",
    "        temp = df_corpus2['content'][i]\n",
    "        all_harder_text.append(temp)\n",
    "        \n",
    "    vec = TfidfVectorizer(stop_words='english', max_features=2000)\n",
    "    vec = vec.fit(all_harder_text)\n",
    "    corpus2_vectors = vec.transform(all_harder_text).toarray()\n",
    "    user_doc = text\n",
    "    user_doc_vector = vec.transform([user_doc]).toarray() \n",
    "    user_doc_vector_short = np.argsort(user_doc_vector)[-25:]\n",
    "    distances = cdist(user_doc_vector_short,\n",
    "                  corpus2_vectors[-25:],\n",
    "                  metric='cosine')[0]\n",
    "    ranking = np.argsort(distances)\n",
    "    top = ranking[0]\n",
    "    best_match = df_corpus2['content'][top]\n",
    "        \n",
    "    print(distances[top])\n",
    "    return (best_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"On one level, this is a business dispute that highlights tensions in the music industry (both intractably ancient and very current). When Swift signed her six-album deal that furnished Big Machine with rights to her masters, she was partaking in a classic arrangement for new artists: handing over future control of music in exchange for start-up promotional, recording, and distribution help. As she’s risen to megastardom, she’s chafed at that arrangement the same way that many successful musicians have chafed at not having ownership of their work. Prince, who famously protested Warner Bros. Records in 1993 by writing the word slave on his cheek, struck a deal for his own back catalog at great cost in 2014. Paul McCartney preached for years about the importance of artists owning music—and one person he preached to, Michael Jackson, ended up buying the rights to the Beatles’ catalog from under him. West himself recently filed suit to gain control of his own masters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7559452332221537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Long-running shows can refer to:\\n\\nLists by country\\nInternational list of longest-running TV shows by category  \\nList of longest-running Australian television series\\nList of longest-running Philippine television series\\nList of longest-running Spanish television series\\nList of longest-running UK television series\\nList of longest-running United States television series\\nList of longest-running U.S. cable television series\\nList of longest-running U.S. primetime television series\\nList of longest-running U.S. syndicated television series\\nList of longest-running U.S. broadcast network television series\\n\\nTheatre\\nLong-running musical theatre productions'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_harder_level(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
